## 一  知识结构

#### 1  递归

1.1  定义递归
1.2  调用递归
1.3  错误使用递归
1.4  使用递归例子
1.5  递归准则

#### 2  相对增长率

2.1  相对增长率的概念
2.2  相对增长率的计算

#### 3  算法分析前提

3.1  计算模型
3.2  分析目标
3.3  示例问题

#### 4  分析运行时间

4.1  时间单元法
4.2  大O分析法
	4.2.1  分析递归

#### 5  分析最大子序列和问题

5.1  两个暴力算法
5.2  分治算法
5.3  线性算法
	5.3.1  联机算法

#### 6  对数运行时间

6.1  折半查找
6.2  辗转相除法
6.3  快速幂算法

## 二  主要内容

​	递归是本书学习的第一个重要算法。递归函数是调用自身的函数，其调用过程和普通函数并无区别。本章展示了几个错误使用递归和正确使用递归的例子，帮助学习者更好地理解递归。递归看似简单，但优秀地使用并不容易；需要遵守递归准则：基准情况、不断推进、设计法则、合成效益法则。

​	相对增长率是算法分析的数学基础。相对增长率在微积分中定义，用于比较函数的增长速度。在算法分析中一般不需要用到微积分，只需要用到几条计算准则和一些一致结论就可以进行简单的计算。
​	算法分析还需要一些前提。需要一个理想的计算模型，算法分析就在其中进行。算法分析的目标是分析最坏运行时间和平均运行时间，默认情况下分析前者。本章将以最大子序列和问题作为示例问题进行算法分析，这是因为这个问题有许多不同优劣的算法。

​	算法分析有两种基本方法：时间单元法和大O分析法。时间单元法逐行分析代码，深入分析细节，得到精确的运行时间单元。在大多数情况下时间单元法太过复杂，并且只关心大O结果，于是可以使用大O分析法。大O分析法给出了一系列分析准则，使分析只需要关注那些可能会成为时间瓶颈的代码段，并最终给出大O的近似结果。
​	对最大子序列和问题的分析使我们看到算法分析是如何进行的。该问题给出了四个算法：两个暴力算法、一个分治算法、一个线性算法，其中第二个暴力算法是在第一个暴力算法的基础上改进得到的。对该问题的分析还使我们看到了优秀算法的价值和算法分析的价值。

​	最后讨论一类特殊的算法，其运行时间含有对数。当算法能划分为不同部分并分别求解时，算法的运行时间中就会有对数；因此分治算法的运行时间常常含有对数。本章给出了三个典型算法：折半查找、辗转相除法和快速幂算法。

## 三  重点梳理

- 掌握递归，理解递归准则，掌握如何优秀地使用递归。
- 掌握算法分析，掌握时间单元法和大O分析法，掌握如何使用大O分析法分析递归。
- 理解最大子序列和问题，理解分析该问题的意义。
- 掌握对数运行时间，掌握三个典型算法：折半查找、辗转相除法、快速幂算法。

## 四  难点解析

#### 1  什么是递归？如何使用递归？递归准则如何指导更好地使用递归？

​	递归从数学定义衍生而来。在数学中，递归是调用自己的函数。算法中的递归与之类似，一个方法如果在方法体中包含它自己的方法调用，则称这个方法是递归的。

​	递归方法需要包含两个部分：基准情况和递归调用。递归方法必须存在某种基准情况，不需要另一次递归调用即可执行本次递归调用并返回。当不属于基准情况时，递归方法必须向某种基准情况推进，并最终推进到这种基准情况的递归调用作为终点。务必小心递归方法不能推进到终点的错误递归使用。
​	递归调用就像普通方法调用一样。首次递归调用时，会产生一个方法调用栈，只是栈中的方法都是相同的方法。作为终点的递归调用不再调用该递归方法，像普通方法调用一样，执行方法并返回。每个递归调用执行并返回，直到首次递归调用向调用者返回结果。

​	递归准则包括以下四条准则：
​	1  基准情况。必须存在某种基准情况，不需要另一次递归调用即可执行并返回。
​	2  不断推进。不属于基准情况时，连续的递归调用必须向某种基准情况推进。
​	3  设计法则。假设所有的递归调用都能正确运行。
​	4  合成效益法则。不要在不同的递归调用中执行相同的递归调用。
​	前两条递归准则指导递归方法设计的基本原则，在之前已经分析过。接下来分析后两条递归准则。

​	设计法则指导我们，设计递归方法时，假设其他递归调用都能正确运行，把目光关注于当前递归调用中，从而能够像设计普通方法一样设计递归方法。
​	考虑一种简单的情况，需要设计一个递归方法$f(n)$，并且将会以不同的参数$n$执行不同的递归调用。首先考虑基准情况下的递归调用，此时的递归方法设计是简单的，就像设计普通方法一样。接下来考虑某个非基准情况的递归调用$f(n_1)$，它需要执行另一个递归调用$f(n_2)$，或者还可能有其它的递归调用。设计法则指导我们，假设所有的递归调用都能正确运行。于是，我们不需要考虑$f(n_2)$应该如何设计或者如何执行；我们只需要假设$f(n_2)$能够正确运行并返回结果，可以像使用变量一样使用$f(n_2)$的返回结果，只需要考虑$f(n_1)$如何使用$f(n_2)$得出结果即可。设计法则使得我们可以像设计普通方法一样设计递归方法，不必关注连续递归调用的复杂细节，只需要考虑当前递归调用即可。

​	合成效益法则指导我们避免设计糟糕的递归方法。动态规划本质上是充分利用合成效益法则的递归算法。
​	考虑斐波那契数列的递归方法$f(n)$，它在方法体中调用$f(n-1)$和$f(n-2)$，并以$f(0)$和$f(1)$作为基准情况。这个递归方法的设计是相当简单的，但它的运行效率却相当糟糕。其原因在于，$f(n-1)$在方法体中又调用$f(n-2)$。当$f(n-1)$返回后，$f(n)$不会记得$f(n-2)$的返回值，于是重新执行$f(n-2)$。于是$f(n-2)$被重复执行了两次，这就造成了浪费。进一步分析，$f(n-3)$会被重复执行三次，$f(n-4)$会被重复执行五次，以此类推。已经执行的方法调用被抛弃，而在某处又重新执行，重复的递归调用递归地合并起来，造成了惊人的浪费。精确的数学分析指出，递归调用数目是以指数形式增长的，因此该递归方法的时间复杂度是指数级的。在$n$很小时执行递归方法就已经成为了不可能。
​	违背合成效益法则的递归方法不仅是降低方法效率那么简单。当递归深度很浅时，递归调用就需要惊人的时间，很容易因为内存限制而引发异常。因此，这样的递归方法是失败的，是根本不可用的。不要违背合成效益法则，就像不要违背其他三条递归法则一样。

#### 2  如何计算相对增长率？

​	相对增长率是数学中的概念，用于衡量两个函数$f(n)$和$g(n)$增长的相对速率。
​	假设$f(n)$和$g(n)$均恒正且单调不减，$n$为正整数，则：
​	1  $f(n)=O(g(n))$：$f(n)$慢于或等于$g(n)$。
​	2  $f(n)=\Omega(g(n))$：$f(n)$快于或等于$g(n)$。
​	3  $f(n)=\Theta(g(n))$：$f(n)$等于$g(n)$。
​	4  $f(n)=o(g(n))$：$f(n)$慢于$g(n)$。注意与$f(n)=O(g(n))$区分，不包括增长率相等的情况。

​	可以用微积分的知识求解相对增长率。求解$\lim\limits_{n \to +\infty} \frac{ f(n) }{ g(n) }$的极限：
​	1  极限为0：$f(n)$慢于$g(n)$。
​	2  极限为正无穷：$f(n)$快于$g(n)$。
​	3  极限为非零常数：$f(n)$等于$g(n)$。
​	其他情况在算法分析中基本上是不可能出现的，可以不考虑。

​	不过，在算法分析中，往往不需要微积分来求解相对增长率。事实上，由于$f(n)$和$g(n)$的形式通常并不复杂，相对增长率的求解只需要简单的代数方法即可。利用本章的几个重要结论和典型函数的相对增长率即可求解。
​	例如，$f(n)=nlogn$和$g(n)=n^{1.5}$求解相对增长率。由于我们关注相对性，从而可以约去$n$，比较$logn$和$n^{0.5}$。给两边平方，这实际上就是比较$log^2n$和$n$。由于任意次幂的对数慢于线性的相对增长率，于是前者增长较慢。于是，得到最终结论，$f(n)$慢于$g(n)$。

​	相对增长率是算法分析的重要概念。通常，$n$表示输入量，例如某个数组的长度或者关键循环的次数；而$f(n)$和$g(n)$分别表示两个算法在输入量$n$下的资源消耗。通过比较相对增长率，就可以比较两个算法在输入量$n$较大时的资源消耗趋势。因此，在算法分析中，希望相对增长率越低越好。

#### 3  算法分析的计算模型是怎样的？分析目标是什么？

​	算法分析需要在一个计算模型中进行。这个计算模型是理想计算模型，但它适用于大部分实际情况。
​	1  该计算模型是一个标准的冯诺依曼结构计算机，并有一个标准的简单指令系统。
​	2  该计算模型执行任何一条简单指令都只需要一个时间单元。四则运算、移位、赋值等指令均包括在内，尽管加法运算和除法运算事实上运行时间相差很大。诸如数组排序或矩阵求逆的操作显然不是简单指令。另外方法分析也不是简单指令。
​	3  该计算模型有无限的内存，不需要考虑缺页中断和磁盘访问等问题，所有的数据都在内存中。这一特点有时不适用实际的情况，此时需要特殊的算法分析；不过，大多数情况还是适用的。

​	算法分析的目的是算法的资源消耗，即时间资源和空间资源。
​	在大多数情况下更关注算法的时间资源。计算机硬件的发展使得空间资源更加廉价，而高性能和高实时性的要求使得时间资源更为紧张。此外，大多数情况下，糟糕的算法并不会消耗过多的空间资源，但可能会消耗过多的时间资源，除非遇到糟糕的递归方法等特殊情况。
​	分析算法的时间资源时，给定输入量$n$，算法消耗的时间资源可用$f(n)$表示。$f(n)$如何计算稍后讲解。虽然还有其他因素的影响，但输入量是最主要也是最容易分析的因素。此外，可能有多个输入量参数。

​	分析算法的时间资源时，通常关注平均情况的时间资源$f_{avg}(n)$和最坏情况的时间资源$f_{worst}(n)$。$f_{avg}(n)$能反映典型的时间资源，在算法被随机重复执行时非常有用；$f_{worst}(n)$则对最坏情况作出保证，使得算法在任何情况下都不至于失控。偶尔也分析最好情况的时间资源，不过大多数情况都没有什么意义。
​	通常情况下都分析最坏情况的时间资源$f_{worst}(n)$，这是因为平均情况的时间资源$f_{avg}(n)$是非常难以计算的，甚至平均的标准为何都难以定义。例如，可以是所有输入情况的算术平均，实际输入情况的加权平均，或者是不同方法调用情况的平均。

​	另外，还要指出，算法分析只针对于算法而不针对语言或程序。给定一个算法，可以用不同的编程语言实现该算法，即使是同样的语言也可以编写出细节不同的程序。通常而言不同的实现只会有不同的细微差距，而算法分析的指导意义依然存在。

​	算法分析在输入量很大的情况下是一个很有意义的工作。如果预计算法的输入量很小，在任何输入情况下都能得到让人满意的结果，那么就没有必要进行算法分析了，除非算法确实极其糟糕。在这种情况下，尝试实现算法并进行一些简单的测试，也许是更好的选择。

#### 4  为什么要学习算法分析？算法分析的意义是什么？

​	算法分析的意义在于：在巨大输入量的情况下，分析算法的资源消耗，设计并优化更好的算法，并尽可能以最佳方式实现算法。

- 巨大输入量：巨大输入量是算法分析的前提。如果输入量很小，那么算法的优劣差距并不明显，甚至于在巨大输入量下更优的算法有可能在小规模输入量下性能更差。
- 分析资源消耗：算法分析有助于快速计算并确定算法的资源消耗，即时间资源和空间资源，特别是在尚未对算法具体实现的情况下。这有助于提前摒弃糟糕的算法，节省编码实现的精力。
- 确定算法瓶颈：算法分析可以快速确定资源消耗的主要瓶颈，并指导如何进行优化，或者确定这一瓶颈确实无法优化从而无需浪费时间。确定算法瓶颈为优化算法提供了有效的指导。
- 提高算法眼界：学习算法分析让我们看到优秀的算法是如何设计的，拥有对于设计优秀算法的洞察能力，从而在最初设计算法时就使用优秀的设计，这比先设计算法再进行改进更有效率。如果不学习算法分析，则算法眼界太低，有可能设计了糟糕的算法而不自知。
- 最佳实现算法：对于一个确定的算法，也可能有许多不同的实现，算法分析能指导我们尽可能地以最佳方式实现算法。

#### 5  如何进行算法分析？分别讲解时间单元法和大O分析法。

​	算法分析确定算法的资源消耗，包括时间资源和空间资源。空间资源主要是变量申请的内存和方法调用的栈内存，分析是简单的，因而接下来主要讲解时间资源。

​	时间单元法首先将算法实现为程序，然后深入分析程序的细节以确定算法运行所需的时间单元。其步骤如下：
​	1  将算法实现为程序。可以使用任何编程语言，也可以使用伪代码。不同的语言和不同的实现可能会使分析结果略有不同，但不会有太大的差异。
​	2  确定时间单元。以Java语言为例，所有的赋值、比较、四则运算均需要一个相同的时间单元，而表达式、条件流程、循环流程的所需时间由时间单元确定。方法的调用过程和返回过程均不计时间，只有执行过程计入。声明可以不计时间，也可以需要一个时间单元，尽管为变量申请内存可能是相当耗时的。
​	3  分析程序细节。逐行分析程序，确定程序的执行流程，深入程序细节，计算程序运行所需的所有时间，以时间单元为单位。
​	4  （可以省略）转换为大O结果。对于输入量$N$，忽略结果的常数项、低阶项和系数，得到大O结果。
​	本章对于时间单元法的执行有一个具体深入的例子，在这里不展开陈述。

​	时间单元法是算法分析的基本方法，它有以下好处：
​	1  结果精确。时间单元法考虑所有程序细节，并保留了常数项、低阶项和系数，这在少数情况下会很有用。如果对于不同的操作采用不同的时间单元，那么分析结果会更加精确。
​	2  针对特定实现。算法可以用不同方式实现，而时间单元法给出了特定实现的运行时间，这在少数情况下可能有用。
​	不过，时间单元法有更多的缺点：
​	1  需要预先编码。时间单元法要求对算法预先编码，即使是简单的伪代码实现。这就要求更多的编码精力，但不同的实现的分析结果是相差不大的。
​	2  转换大O结果。很多情况下，尤其是在巨大输入量的情况下，其实并不需要算法运行的精确时间，而只需要算法运行时间的大O结果。于是，精确分析的细节被抛弃，所得到的结果和大O分析法的结果相同，因此花费了更多的时间却没有得到更多的回报，这是不值得的。
​	因此，绝大多数情况下都使用大O分析法，极少用到时间单元法，除非确实需要精确结果。

​	大O分析法的基本原则是：
​	1  得到近似结果。这意味着，低阶项和常数项可以被抛弃，而系数也可以被省略。这使得分析过程可以节省大量的精力。例如，具体地说，如果一个算法中存在与输入量$N$有关的二次循环，那么所有一次循环和普通语句都没有必要关注了，因为他们在结果中会被忽略；循环内部的语句若与$N$无关，则也不需要关注，因为它们不过是最后结果的$N^2$的系数。
​	2  考虑最坏结果。由于大O结果提供的是上界，因此必须保守，不能低估算法的运行时间。分析结果可以过高，但决不能过低。例如，一个与输入量$N$有关的循环中有一个`break`语句，这使得循环可能提前结束。可是，由于无法确定循环是否以及何时跳出，因此必须考虑最坏结果，即循环会执行$N$次。

​	于是，我们得到大O分析法的基本方法（设$N$为输入量）：
​	1  忽略普通语句。诸如赋值、移位、比较、计算这样的普通语句没有必要关注，除非它们的运行时间与$N$有关，不过这种情况是很少遇到的。声明也可以忽略。
​	2  关注执行流程。关注顺序流程、条件流程、循环流程，特别是循环流程的循环次数很可能与$N$有关，从而成为分析结果的主要因素。如果存在多层循环，则从内向外地分析循环，并关注每层循环的循环次数。
​	3  关注方法调用。如果存在方法调用，则首先分析方法调用，并将其运行时间考虑到最终结果。
​	4  关注递归。递归方法的分析通常是很困难的。如果知道递归方法实际在做什么，分析可能很简单；否则，大部分情况下都需要精确地分析，并求解一个递推数列。主要关注递归调用的层数以及每次递归调用的运行时间。
​	本章有很多使用大O分析法分析运行时间的例子，这里不展开深入。

​	大O分析法和时间单元法不是孤立使用的。事实上，相当多的情况是，先使用大O分析法对算法进行分析，对于那些需要仔细分析的算法细节再使用时间单元法。大O分析法为主，时间单元法为辅是算法分析的主要方法，可以得出相对满意的结果，并且所需要的精力也不会太多。

#### 6  对最大子序列和问题的分析有什么意义？

​	最大子序列和问题以及求解该问题的四个算法都已在本章给出，不再赘述。

​	算法一是一个简单直接的算法，它以最简单的方式求解问题，并且没有任何优化。这个算法的思考和编码都很简单，但它的运行效率相当低下。算法一让我们看到了，不学习算法分析而设计的粗陋算法是多么地无用，算法看上去没有任何问题，但可能隐藏着巨大的时间开销。如果学习了算法分析，从一开始就能避免设计这样的算法，即使设计了这样的算法也能很快察觉到问题所在，而不至于设计了粗陋的算法却不自知。

​	算法二也是一个简单直接的算法，但它对算法一作出了一定的优化。算法二通过撤除一个循环，使原来的三层循环变为二层循环，从而算法的性能得到了大大的提高；二次运行时间在大多数中等规模的输入量下都是可接受的。算法二使我们看到学习算法分析的价值所在：无需过多精力，通过简单的优化即可大大提高算法的性能，这无疑是非常划算的。学习算法分析之后，在大多数情况下，只要能作出算法二的程度的优化即可，即改进使得程序性能变差的明显瓶颈。

​	算法三使用一个精心设计的分支算法，将时间复杂度降低到$O(NlogN)$。如果没有线性时间的算法四，算法三就会是体现算法分析威力的极好示例了。算法二尽管经过了一定的优化，但还不能称之为优秀的算法；算法三比起算法二的性能有了明显的提高，并且能够处理大规模的输入量。没有学习过算法分析的程序员也许能做出从算法一到算法二的优化，但设计算法三是几乎不可能的，即使学习过算法分析，设计算法三也需要深厚的算法分析功底。这正是区分优秀程序与普通程序，优秀程序员与普通程序员的差距所在。

​	算法四是一个线性算法。进一步地，它是联机的，因而几乎是完美的算法。算法四几乎没有实际意义，因为大多数问题都不存在理想情况下的完美算法；即使存在，设计这样的算法也需要大量的精力和时间，在大多数情况下是不值得的。对于绝大多数问题，只要能设计出算法三的级别的算法，就已经是令人满意的结果。因此，算法四更多是理论上的意义，让程序员向理想算法的方向努力。

#### 7  算法运行时间中为何会出现对数？对数运行时间的规律是什么？

​	对数时间的出现规律是：如果算法在$O(f(N))$时间内将问题的规模削减为固定比例的部分，则这个算法是$O(f(N)logN)$的；如果算法在$O(f(N))$时间内将问题的规模削减为固定大小的部分，则这个算法是$O(f(N)*N)$的。
​	例如，折半查找在常数时间内将查找范围削减为原来的一半，因此这一过程只需要$O(logN)$次，运行时间是$O(logN)$。如果另一个算法在线性时间内将问题的规模削减为原来的五分之三，则这一过程需要$O(log_{\frac{3}{5}}N)$次，而运行时间是$O(N * logN)$。

​	从上述规律可以发现，对数时间和递归算法联系紧密，因为递归算法可以递归地求解不同的子问题。进一步地说，对数时间和分治算法联系紧密，因为分治算法正是将问题分解为子问题，递归地求解子问题，并做一些附加的工作将子问题的结果合并为整个问题的结果的过程。事实上，对数时间出现的大多数算法都是分治算法。

## 五  重要图表

- P6  错误使用递归
  ![错误使用递归](D:\Learn\Note\Programming\数据结构与算法分析基础\Image\1 算法分析基础\错误使用递归.png)
- **P21  典型的相对增长率**
  ![典型的相对增长率](D:\Learn\Note\Programming\数据结构与算法分析基础\Image\1 算法分析基础\典型的相对增长率.png)
- P26 & P27  最大子序列和问题的两个暴力算法
  ![最大子序列和问题的暴力算法_1](D:\Learn\Note\Programming\数据结构与算法分析基础\Image\1 算法分析基础\最大子序列和问题的暴力算法_1.png)
  ![最大子序列和问题的暴力算法_2](D:\Learn\Note\Programming\数据结构与算法分析基础\Image\1 算法分析基础\最大子序列和问题的暴力算法_2.png)
- **P29  最大子序列和问题的分治算法**
  ![最大子序列和问题的分治算法](D:\Learn\Note\Programming\数据结构与算法分析基础\Image\1 算法分析基础\最大子序列和问题的分治算法.png)
- **P30  最大子序列和问题的线性算法**
  ![最大子序列和问题的线性算法](D:\Learn\Note\Programming\数据结构与算法分析基础\Image\1 算法分析基础\最大子序列和问题的线性算法.png)
- P31  折半查找算法
  ![折半查找算法](D:\Learn\Note\Programming\数据结构与算法分析基础\Image\1 算法分析基础\折半查找算法.png)
- P32  辗转相除法
  ![辗转相除法](D:\Learn\Note\Programming\数据结构与算法分析基础\Image\1 算法分析基础\辗转相除法.png)
- P33  快速幂算法
  ![快速幂算法](D:\Learn\Note\Programming\数据结构与算法分析基础\Image\1 算法分析基础\快速幂算法.png)

## 六  薄弱点清单



------

